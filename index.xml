<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kevin Wong</title>
    <link>http://kevinfw.com/index.xml</link>
    <description>Recent content on Kevin Wong</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Kevin Wong</copyright>
    <lastBuildDate>Mon, 05 Dec 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Blogging with R Markdown</title>
      <link>http://kevinfw.com/post/blogging-with-r-markdown/</link>
      <pubDate>Mon, 05 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>http://kevinfw.com/post/blogging-with-r-markdown/</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;Throughout my graduate studies, I’ve used R quite a bit and have grown fond of it. When it comes to doing data science and machine learning, R fits the bill nicely. Not to mention R has a huge following and is currently one of the most popular languages in the world. As a result, it has a very active community and a huge selection of packages that pretty much allows R to do anything you want like reproducible reporting.&lt;/p&gt;
&lt;p&gt;One of the key skills of a data scientist is to communicate and share your analyses/models with your peers or stakeholders. If you can’t effectively show what you did, then what’s the point? The guys at RStudio have created a great solution called R Markdown. If you’ve ever used Markdown, then you know how easy it is. R Markdown allows one to embed R code into a reporting document. Just start a new .Rmd file in RStudio and adjust the YAML front matter at the very top of the document and you’re good to go. R Markdown borrows the syntax from vanilla Markdown where most of the difference is in parameterizing the code chunks. R Markdown is amazing for reproducibility. Also, anyone that’s ever seen a R Markdown document knows it’s one of the prettier looking documents. R Markdown even has the capability to embed Shiny apps/interactive widgets.&lt;/p&gt;
&lt;p&gt;However, there is one drawback to R Markdown right now and that’s blogging. In an ideal world, I would be in RStudio, writing a post in R Markdown and pushing it to github pages and be done with it. But it’s not there yet. I’ve seen many solutions from using Jekyll (which I haven’t found to be easy) to spinning up your own AWS EC2 instance and setting up a blog there to host html files. Most seem like more work than it should be just to put up a nice looking R Markdown page. After much searching around, I found &lt;a href=&#34;https://github.com/rstudio/blogdown&#34;&gt;blogdown&lt;/a&gt; by Yihui Xie, the man who created Knitr. Blogdown uses &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;, a blogging framework for static pages built using the &lt;a href=&#34;https://golang.org/&#34;&gt;Go&lt;/a&gt; language. One word of warning, blogdown is still under development, but I’ve tested it out and there have been minor issues, but most of it is because there is no documentation right now if you’re stuck. I’ve had to go under the hood and look at the code to figure out what functions to run. Below I’ll show a quick way to get set up so that blogging with R Markdown is joy from start to finish.&lt;/p&gt;
&lt;p&gt;Assuming you already have R/RStudio installed, you’ll need to download the blogdown package to your machine like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;#39;rstudio/blogdown&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, you’ll need to install Hugo to your local machine using the blogdown function &lt;code&gt;install_hugo()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::install_hugo()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we can create a new directory for our webpage and make sure to set your working directory to that new directory. Once in your empty directory, run the following command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::new_site()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the above does not work, make sure you are creating a completely empty directory. I ran into a few issues when I tried to run the above function on a directory with a .Rproj file in it. So remember, the directory will need to be &lt;em&gt;totally empty&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The above command will generate all the necessary skeleton files needed to generate the blog and launch it in the console. It will also show a preview of your blog in the viewer window in RStudio. The above command also automatically downloads a theme, but this can easily be changed if you choose with the below command. You can find more Hugo themes at &lt;a href=&#34;themes.gohugo.io&#34;&gt;here&lt;/a&gt;. My current theme is academic. You can change it to whatever you want by specifying the github repo and the theme name as shown below in quotes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::install_theme(&amp;#39;gcushen/hugo-academic&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Keep in mind when you install a new theme, the config file &lt;code&gt;config.toml&lt;/code&gt; will update to use the most recently downloaded theme as default. So to change it in the future just go into the &lt;code&gt;config.toml&lt;/code&gt; file and adjust the &lt;code&gt;theme =&lt;/code&gt; parameter to the name of the theme you want.&lt;/p&gt;
&lt;p&gt;When you’re happy with the theme, it’s good practice to preview your blog before pushing it out to the world. Run the following in your console:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::serve_site()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will generate the blog and preview it on your local machine. Blogdown loads your website on your localhost IP address. Mine shows up here: &lt;code&gt;http://127.0.0.1:4321/&lt;/code&gt;. If you’re using RStudio, you’ll be able to preview the site/post and make changes on the fly. When you make changes to the R Markdown document being previewed, blogdown will rebuild the website when you hit save and the Viewer in RStudio will automatically show the updated content. You can also use &lt;code&gt;blogdown::build_site()&lt;/code&gt; to build the site for publishing, but it will not preview it. Hugo generates the published content in the &lt;code&gt;public/&lt;/code&gt; directory of your root.&lt;/p&gt;
&lt;p&gt;When you create a new Rmd file in RStudio, a date will automatically be propogated for you in the &lt;code&gt;&amp;quot;December 5, 2016&amp;quot;&lt;/code&gt; format in the YAML front matter. Hugo will not be able to correctly parse this date when it builds the website and will throw an error. So make sure to manually change the date to this format &lt;code&gt;&amp;quot;2016-12-06&amp;quot;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you followed those basic steps then you should have the website files in the &lt;code&gt;public/&lt;/code&gt; directory and you’re good to go. I won’t show you how to put your blog posts online as everyone has their preference for blogging platform. I personally use github pages because it’s free and having version control with your blog posts is nice. Blogdown is a good complement because I don’t have to worry converting &lt;code&gt;.Rmd&lt;/code&gt; files to &lt;code&gt;.md&lt;/code&gt; files and put plot figures in separate folders; it’s all done for me.&lt;/p&gt;
&lt;p&gt;Remember, blogdown is still under development so many people are bound to run into errors and the lack of documentation doesn’t help. To their credit, the RStudio guys are busy making our lives better. Blogdown is a great start to easy blogging in R Markdown. And I look forward to more developments coming to this package.&lt;/p&gt;
&lt;p&gt;I hope this post helped some of you out there like me who love R Markdown and want to easily share these type of documents. Happy R Markdown blogging!&lt;/p&gt;



&lt;!-- BLOGDOWN-HEAD






/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>First Post using Hugo</title>
      <link>http://kevinfw.com/post/first-post-using-hugo/</link>
      <pubDate>Sun, 04 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>http://kevinfw.com/post/first-post-using-hugo/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve used many different frameworks and platforms for blogging from Blogspot to Wordpress to Ghost to Jekyll. R Markdown is awesome, but it&amp;rsquo;s never been easy to share R Markdown documents on any of those platforms. Hugo is another blogging framework, which I&amp;rsquo;ve heard great things about. It compiles very quickly and has little dependencies to worry about compared to Jekyll. I&amp;rsquo;m going to give it a try and hopefully it will play nicely with R Markdown. Looking forward to the adventure!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MSPA Review and the Data Science Path</title>
      <link>http://kevinfw.com/post/mspa-review-and-path-to-data-science/</link>
      <pubDate>Tue, 13 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>http://kevinfw.com/post/mspa-review-and-path-to-data-science/</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;One of the most interesting things about data science is the diversity of practitioners’ backgrounds. I’ve met people who are very science-y (Physics, Astronomy) to very technical (Computer Science, Mathematics) to very business-y (Marketing, IT). There is no definitive path to data science aside from getting a MS or PhD in Statistics or Computer Science since data science involves statistics and software development skills. It’s the most interesting field currently with lots of freedom to explore, to build, to learn, and to shape the future. It’s a very exciting time for data science applications.&lt;/p&gt;
&lt;p&gt;Everytime I meet people and tell them that I’m a graduate student in predictive analytics at Northwestern University, a lot of people always ask me if the program is worth it. The short answer is that it’s a great program. You learn the necessary math (linear algebra, statistics, probability), programming languages (R, Python, SAS), and applications (data cleaning, statistical analysis, machine learning, data visualization) to be a contender for data science jobs.&lt;/p&gt;
&lt;p&gt;Another question I get asked often is, “Is a degree necessary to get into data science?” Honestly, I don’t think I’m qualified to answer that since I’m a student and am looking for a job myself, but my personal belief is that I prefer getting a degree over certifications from MOOCs because of the structure it enforces. MOOCs and self-taught courses have too little structure and accountability in my opinion. I know lots of people want to get into the fast lane into data science, but the honest truth is it takes time, work, and thought. Something that just can’t be mastered in a two month bootcamp. Obviously, a lot of this largely depends on your background, your natural abilities, and how you put yourself out there.&lt;/p&gt;
&lt;p&gt;But there is always a disclaimer, something I learned over the past year, that I give people and that’s having a degree in something doesn’t guarantee anything. The degree gets you half way there, the other half relies on your ability to share your work, network with others, and be persistent in improving yourself.&lt;/p&gt;
&lt;p&gt;I’ve been a part of the MSPA program for a little over a year now and I am 75% done (9/12 courses through). I’ll go over in little detail of each category I feel is important to making that choice to pursue the degree.&lt;/p&gt;
&lt;div id=&#34;reputation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reputation&lt;/h3&gt;
&lt;p&gt;Northwestern University is a top notch institution. There are lots of universities offering data science degrees, but not many with NU’s reputation of world class education. Northwestern University was actually one of the first institutions to offer a degree in analytics (online), so that says a lot about their understanding of the field. They are constantly refining the course offerings to match the skills needed for a modern data scientist.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;faculty&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Faculty&lt;/h3&gt;
&lt;p&gt;Professors are for the most part great. They each have a wealth of experience in the field and are experts in their field. Some are better than others, but that’s just normal variation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;courses&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Courses&lt;/h3&gt;
&lt;p&gt;This subject probably matters the most to people. In the program, you will learn math. You will also learn theory that’s necessary for you to be an effective practitioner of analytics. So expect topics like data cleaning, statistical analysis, model evaluation, and machine learning.&lt;/p&gt;
&lt;p&gt;You will learn about the popular programming languages–R, Python, SAS. But likely, you won’t master them in this program. However, you will be challenged to at least become proficient. There are usually lots of extra material to expand your abilities in whatever language is used in the course and you will learn a lot from professors and peers, who may know more programming than you do.&lt;/p&gt;
&lt;p&gt;The courses will challenge you and teach you to be a practitioner of data science. However, don’t expect to become an expert in mathematical theory. You will understand just enough to get the job done.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;network&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Network&lt;/h3&gt;
&lt;p&gt;I found that students in all my classes have always been very active, very friendly, and very intelligent. There is a very strong network of students/alumnis of the program on LinkedIn. Everyone is friendly and always willing to give advice. For many, the LinkedIn groups are the central hub of the MSPA program. You will find a lot of guidance and questions answered there. There is also a career center, but be prepared to take the initiative. You won’t get any help if you don’t ask for it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;value&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Value&lt;/h3&gt;
&lt;p&gt;Lastly, the price is on the higher end. Currently, the cost of one course is just north of $4k. The total required courses to complete the degree is 12. So do the math and you get a grand total of about $48k. There are others that are more expensive like Berkeley’s master in data science which costs about $60k last time I checked. There are a few other various degree programs out there that costs less than $20k. And obviously, there are bootcamps that are even cheaper (less than $10k) with guarantees to get you a job, although I’ve met people in these bootcamps that mention it’s not as great as it sounds.&lt;/p&gt;
&lt;p&gt;So overall, you’ll learn a lot. You will be able to do data science after this program. You will become qualified for an entry data science job. But remember, whatever your path to get there, it’s the little details that matter like having a github page that showcases your code or going to a meetup and talking to people about data science.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-suggestions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further Suggestions&lt;/h3&gt;
&lt;p&gt;I think the program can benefit from teaching students the proper workflow of a data scientist. I know this can be subjective, but one of the hardest things for newbies is how to get started and how to develop a systematic pipeline for gathering data, doing analyses, and building models. Also, learning how to work with big data by learning how to do that with distributed computing systems like Hadoop, Spark, etc.&lt;/p&gt;
&lt;/div&gt;



&lt;!-- BLOGDOWN-HEAD






/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Scraping NBA Stats From The Web</title>
      <link>http://kevinfw.com/post/web-scraping-with-r/</link>
      <pubDate>Sat, 11 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>http://kevinfw.com/post/web-scraping-with-r/</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;Web scraping using R is a fairly easy task. Let’s take a look at the Coach of the Year statistics from the ESPN.com site. First install the necessary packages. &lt;code&gt;rvest&lt;/code&gt; allows you to extract data from a webpage. &lt;code&gt;stringr&lt;/code&gt; allows you to manipulate strings. &lt;code&gt;tidyr&lt;/code&gt; will load the data manipulation libraries that’ll be useful for selecting and munging data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;#39;rvest&amp;#39;)
install.packages(&amp;#39;stringr&amp;#39;)
install.packages(&amp;#39;tidyr&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We add an extra library here because &lt;code&gt;html_nodes()&lt;/code&gt; function fails when not run interactively. Load the following libraries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rvest)
library(stringr)
library(tidyr)
library(methods)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Read the wepage in:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url &amp;lt;- &amp;#39;http://www.espn.com/nba/history/awards/_/id/34&amp;#39;
site &amp;lt;- read_html(url)
coach_table &amp;lt;- html_nodes(site, &amp;#39;table&amp;#39;)
coaches &amp;lt;- html_table(coach_table,fill=TRUE)[[1]]
head(coaches)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  X1                X2                    X3
## 1 Coach of the Year Coach of the Year     Coach of the Year
## 2              YEAR             COACH                  TEAM
## 3              2016        Steve Kerr Golden State Warriors
## 4              2015  Mike Budenholzer         Atlanta Hawks
## 5              2014    Gregg Popovich     San Antonio Spurs
## 6              2013       George Karl        Denver Nuggets
##                  X4                X5                X6                X7
## 1 Coach of the Year Coach of the Year Coach of the Year Coach of the Year
## 2               W-L      PLAYOFFS W-L        CAREER W-L               EXP
## 3              73-9              15-9            161-28           2 years
## 4             60-22               8-8           158-112           3 years
## 5             62-20              16-7          1108-490          20 years
## 6             57-25               2-4          1175-824          27 years
##                  X8                X9               X10
## 1 Coach of the Year Coach of the Year Coach of the Year
## 2              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;
## 3              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;
## 4              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;
## 5              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;
## 6              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;              &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are extra rows and columns we don’t need so we’ll remove them and give names to the remaining columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coaches &amp;lt;- coaches[-(1:2), -(8:10)]
names(coaches) &amp;lt;- c(&amp;quot;year&amp;quot;, &amp;quot;coach&amp;quot;, &amp;quot;team&amp;quot;, &amp;quot;season_record&amp;quot;,&amp;quot;playoff_record&amp;quot;,&amp;quot;career_record&amp;quot;,&amp;quot;experience&amp;quot;)
coaches$year &amp;lt;- as.integer(coaches$year)
head(coaches)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   year            coach                  team season_record playoff_record
## 3 2016       Steve Kerr Golden State Warriors          73-9           15-9
## 4 2015 Mike Budenholzer         Atlanta Hawks         60-22            8-8
## 5 2014   Gregg Popovich     San Antonio Spurs         62-20           16-7
## 6 2013      George Karl        Denver Nuggets         57-25            2-4
## 7 2012   Gregg Popovich     San Antonio Spurs         50-16           10-4
## 8 2011    Tom Thibodeau         Chicago Bulls         62-20            9-7
##   career_record experience
## 3        161-28    2 years
## 4       158-112    3 years
## 5      1108-490   20 years
## 6      1175-824   27 years
## 7      1108-490   20 years
## 8       261-157    2 years&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll want to split up some columns and convert them to integers. Those are the &lt;code&gt;season_record&lt;/code&gt;, &lt;code&gt;playoff_record&lt;/code&gt;, and &lt;code&gt;career_record&lt;/code&gt; columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coaches &amp;lt;- separate(coaches, season_record, c(&amp;#39;season_wins&amp;#39;, &amp;#39;season_losses&amp;#39;), sep=&amp;#39;-&amp;#39;, remove=TRUE, convert=TRUE)
head(coaches)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   year            coach                  team season_wins season_losses
## 3 2016       Steve Kerr Golden State Warriors          73             9
## 4 2015 Mike Budenholzer         Atlanta Hawks          60            22
## 5 2014   Gregg Popovich     San Antonio Spurs          62            20
## 6 2013      George Karl        Denver Nuggets          57            25
## 7 2012   Gregg Popovich     San Antonio Spurs          50            16
## 8 2011    Tom Thibodeau         Chicago Bulls          62            20
##   playoff_record career_record experience
## 3           15-9        161-28    2 years
## 4            8-8       158-112    3 years
## 5           16-7      1108-490   20 years
## 6            2-4      1175-824   27 years
## 7           10-4      1108-490   20 years
## 8            9-7       261-157    2 years&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s do the same for &lt;code&gt;playoff_record&lt;/code&gt; and &lt;code&gt;career_record&lt;/code&gt; variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coaches &amp;lt;- separate(coaches, playoff_record, c(&amp;#39;playoff_wins&amp;#39;, &amp;#39;playoff_losses&amp;#39;), sep=&amp;#39;-&amp;#39;, remove=TRUE, convert=TRUE)
coaches &amp;lt;- separate(coaches, career_record, c(&amp;#39;career_wins&amp;#39;, &amp;#39;career_losses&amp;#39;), sep=&amp;#39;-&amp;#39;, remove=TRUE, convert=TRUE)
head(coaches)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   year            coach                  team season_wins season_losses
## 3 2016       Steve Kerr Golden State Warriors          73             9
## 4 2015 Mike Budenholzer         Atlanta Hawks          60            22
## 5 2014   Gregg Popovich     San Antonio Spurs          62            20
## 6 2013      George Karl        Denver Nuggets          57            25
## 7 2012   Gregg Popovich     San Antonio Spurs          50            16
## 8 2011    Tom Thibodeau         Chicago Bulls          62            20
##   playoff_wins playoff_losses career_wins career_losses experience
## 3           15              9         161            28    2 years
## 4            8              8         158           112    3 years
## 5           16              7        1108           490   20 years
## 6            2              4        1175           824   27 years
## 7           10              4        1108           490   20 years
## 8            9              7         261           157    2 years&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, remove the character &lt;code&gt;years&lt;/code&gt; from the experience column and make it an integer. But hold on, there’s actually an easier way. We can use the &lt;code&gt;extract_numeric()&lt;/code&gt; function (update: this function has been deprecated) to get the numbers and remove the old column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coaches$yrs_exp &amp;lt;- as.integer(extract_numeric(coaches$experience))
coaches$experience &amp;lt;- NULL
head(coaches)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   year            coach                  team season_wins season_losses
## 3 2016       Steve Kerr Golden State Warriors          73             9
## 4 2015 Mike Budenholzer         Atlanta Hawks          60            22
## 5 2014   Gregg Popovich     San Antonio Spurs          62            20
## 6 2013      George Karl        Denver Nuggets          57            25
## 7 2012   Gregg Popovich     San Antonio Spurs          50            16
## 8 2011    Tom Thibodeau         Chicago Bulls          62            20
##   playoff_wins playoff_losses career_wins career_losses yrs_exp
## 3           15              9         161            28       2
## 4            8              8         158           112       3
## 5           16              7        1108           490      20
## 6            2              4        1175           824      27
## 7           10              4        1108           490      20
## 8            9              7         261           157       2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There we have it! We have a tidy data frame in which we can do some analysis now! For example, we can figure out which team has the most Coach of the Years using the &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;ggplot2&lt;/code&gt; packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)
coaches %&amp;gt;% select(team) %&amp;gt;% ggplot(aes(team), fill=team) + geom_bar() + coord_flip()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;#####../content/post/web-scraping-with-r_files/figure-html/ggplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So it looks like the Atlanta Hawks and the Chicago Bulls have had some pretty coaches throughout NBA history. There’s much more analysis that can be done with this dataset. We can ask questions like which coach has the most wins all-time? Or we can try to make interesting connections like, do years of experience correlate with more wins? But I’ll leave that to you to find out!&lt;/p&gt;
&lt;p&gt;It’s a good idea to save your data frame to use later:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;write.csv(coaches, &amp;#39;coaches.csv&amp;#39;, row.names=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are other considerations when it comes to scraping and parsing web data like missing values. We can take a look at more of the data and notice some NA values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(coaches, 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    year            coach                   team season_wins season_losses
## 3  2016       Steve Kerr  Golden State Warriors          73             9
## 4  2015 Mike Budenholzer          Atlanta Hawks          60            22
## 5  2014   Gregg Popovich      San Antonio Spurs          62            20
## 6  2013      George Karl         Denver Nuggets          57            25
## 7  2012   Gregg Popovich      San Antonio Spurs          50            16
## 8  2011    Tom Thibodeau          Chicago Bulls          62            20
## 9  2010     Scott Brooks  Oklahoma City Thunder          50            32
## 10 2009       Mike Brown    Cleveland Cavaliers          66            16
## 11 2008      Byron Scott    New Orleans Hornets          56            26
## 12 2007     Sam Mitchell        Toronto Raptors          47            35
## 13 2006    Avery Johnson       Dallas Mavericks          60            22
## 14 2005    Mike D&amp;#39;Antoni           Phoenix Suns          62            20
## 15 2004      Hubie Brown      Memphis Grizzlies          50            32
## 16 2003      Hubie Brown      Memphis Grizzlies          28            41
## 17   NA   Gregg Popovich      San Antonio Spurs          60            22
## 18 2002    Rick Carlisle        Detroit Pistons          50            32
## 19 2001      Larry Brown     Philadelphia 76ers          56            26
## 20 2000       Doc Rivers          Orlando Magic          41            41
## 21 1999    Mike Dunleavy Portland Trail Blazers          35            15
## 22 1998       Larry Bird         Indiana Pacers          58            24
##    playoff_wins playoff_losses career_wins career_losses yrs_exp
## 3            15              9         161            28       2
## 4             8              8         158           112       3
## 5            16              7        1108           490      20
## 6             2              4        1175           824      27
## 7            10              4        1108           490      20
## 8             9              7         261           157       2
## 9             2              4         347           220       0
## 10           10              4         347           216       0
## 11            7              5         454           647      15
## 12            2              4         185           243       6
## 13           14              9         254           186       6
## 14            9              6         472           433      12
## 15            0              4         424           489      13
## 16           NA             NA         424           489      13
## 17           16              8        1108           490      20
## 18            4              6         666           489      14
## 19           12             11        1098           904       0
## 20           NA             NA         770           560      17
## 21            7              6         613           716      17
## 22           10              6         147            67       3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because this is a small dataset, we could infer what those missing values could be. For example, there is a missing value in &lt;code&gt;year&lt;/code&gt; of row 17, which is obvious it should be &lt;code&gt;2002&lt;/code&gt;. So we could manually impute that value.&lt;/p&gt;
&lt;p&gt;There are NAs in the &lt;code&gt;playoff_wins&lt;/code&gt; and &lt;code&gt;playoff_losses&lt;/code&gt; columns. Those are a little trickier and one could possibly impute with more complex methods. But if you have some domain knowledge in sports, you know it’s possible for coaches to win Coach of the Year, but not make it to the playoffs hence the NA values under those columns. So it might be sensible to manually impute with &lt;code&gt;0&lt;/code&gt; or some other value. Although that’s a whole another discussion about imputation techniques and feature engineering which I’ll try to cover in another blog post. Hope that was a quick and helpful introduction to pulling data from the web in R!&lt;/p&gt;



&lt;!-- BLOGDOWN-HEAD






/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>http://kevinfw.com/project/deep-learning/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://kevinfw.com/project/deep-learning/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>http://kevinfw.com/project/example-external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://kevinfw.com/project/example-external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Data Science Tools</title>
      <link>http://kevinfw.com/post/data-science-tools/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://kevinfw.com/post/data-science-tools/</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;One of the most talked about things in the data science community is tooling. What is the best programming language to learn? What IDE should one use? There is no one definitive answer here, but the general answer largely depends on what you’re trying to accomplish and what features you care about and what your workflow is like.&lt;/p&gt;
&lt;p&gt;When I started learning data science, I was overwhelmed by how many tools were out there. Trying to learn every single one is a rather ineffective approach from personal experience. I’ve since focused on mastering one language and one tool and it has helped my understanding of data science and workflow productivity tremendously. That’s not to say you shouldn’t learn others when necessary, but my preference is to be the “master of one” than the “jack of all trades who is the master of none”. Mastering one language and one tool will make learning others so much easier in the long run. But that’s besides the point.&lt;/p&gt;
&lt;p&gt;Below is a list of tools that I prefer when working with a particular language or working in a specific environment, but there are many more out there:&lt;/p&gt;
&lt;div id=&#34;r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;R&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;RStudio: quintessential IDE for working in R. I use this everyday.&lt;/li&gt;
&lt;li&gt;Jupyter Notebooks: I tend to use this when I’m working in R on a server.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;python&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Python&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Anaconda: great Python distribution installer that comes with all the tools like Jupyter Notebooks and data science libraries.&lt;/li&gt;
&lt;li&gt;PyCharm: strong IDE for specifically working in Python. Great debugging features.&lt;/li&gt;
&lt;li&gt;Enthought Canopy: An alternative to Anaconda.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;sas&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;SAS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SAS Studio: This is what I used in grad school so I’ve stuck with it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;unix&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Unix&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cmder / Putty: for ssh’ing to servers using Windows because the Windows Command Prompt is just bad.&lt;/li&gt;
&lt;li&gt;Vim: There’s a whole debate about Vim vs. Emacs. I prefer Vim for quick text editing. Emacs is an ecosystem in it of itself. -Git: not much to say here. It’s necessary to have good understanding of version control when working with code.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;notes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Notes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Microsoft OneNote: awesome for taking notes and creating pages. Similar to Evernote. You can also paste graphics in it. Widely available in most OS now.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;data-viz&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data Viz&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ggplot2: my go to because the graphics are just beautiful.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That’s a short list of the tools I use. If you feel like there are better ones definitely let me know!&lt;/p&gt;
&lt;/div&gt;



&lt;!-- BLOGDOWN-HEAD






/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>A Person Re-Identification System For Mobile Devices</title>
      <link>http://kevinfw.com/publication/person-re-identification/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>http://kevinfw.com/publication/person-re-identification/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mobile visual clothing search</title>
      <link>http://kevinfw.com/publication/clothing-search/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>http://kevinfw.com/publication/clothing-search/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
